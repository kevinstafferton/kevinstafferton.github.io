<!DOCTYPE html>
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
<!-- three.js library -->
<script src='js/three.js'></script>
<script src="js/loaders/GLTFLoader.js"></script>
<!-- ar.js -->
<script src="js/ar.min.js"></script>

<body style='margin : 0px; overflow: hidden; font-family: Monospace;'>
    <script>
        //////////////////////////////////////////////////////////////////////////////////
        // Init
        //////////////////////////////////////////////////////////////////////////////////

        // init renderer
        var renderer = new THREE.WebGLRenderer({
            antialias: true,
            alpha: true
        });
        renderer.setClearColor(new THREE.Color('lightgrey'), 0)
        renderer.setSize(640, 480);
        renderer.domElement.style.position = 'absolute'
        renderer.domElement.style.top = '0px'
        renderer.domElement.style.left = '0px'
        document.body.appendChild(renderer.domElement);

        // array of functions for the rendering loop
        var onRenderFcts = [];

        // init scene and camera
        var scene = new THREE.Scene();
        var clock = new THREE.Clock();
        var mixer;

        //////////////////////////////////////////////////////////////////////////////////
        // Initialize a basic camera
        //////////////////////////////////////////////////////////////////////////////////

        // Create a camera
        var camera = new THREE.Camera();
        scene.add(camera);

        //////////////////////////////////////////////////////////////////////////////////
        // Add lights
        //////////////////////////////////////////////////////////////////////////////////

        var ambientLight = new THREE.AmbientLight(0xffffff, 1);
        scene.add(ambientLight);

        var pointLight = new THREE.PointLight(0xffffff, 1);
        pointLight.y = 2;
        scene.add(pointLight);

        var pointLight2 = new THREE.PointLight(0xffffff, 1);
        pointLight2.z = 2;
        scene.add(pointLight2);

        ////////////////////////////////////////////////////////////////////////////////
        // Handle arToolkitSource
        ////////////////////////////////////////////////////////////////////////////////

        var arToolkitSource = new THREEx.ArToolkitSource({
            // to read from the webcam
            sourceType: 'webcam',

            // // to read from an image
            // sourceType : 'image',
            // sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/images/img.jpg',

            // to read from a video
            // sourceType : 'video',
            // sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/videos/headtracking.mp4',
        })

        arToolkitSource.init(function onReady() {
            onResize()
        })

        // handle resize
        window.addEventListener('resize', function () {
            onResize()
        })
        function onResize() {
            arToolkitSource.onResize()
            arToolkitSource.copySizeTo(renderer.domElement)
            if (arToolkitContext.arController !== null) {
                arToolkitSource.copySizeTo(arToolkitContext.arController.canvas)
            }
        }
        ////////////////////////////////////////////////////////////////////////////////
        // Initialize arToolkitContext
        ////////////////////////////////////////////////////////////////////////////////


        // create atToolkitContext
        var arToolkitContext = new THREEx.ArToolkitContext({
            cameraParametersUrl: 'data/camera_para.dat',
            detectionMode: 'mono',
        })
        // initialize it
        arToolkitContext.init(function onCompleted() {
            // copy projection matrix to camera
            camera.projectionMatrix.copy(arToolkitContext.getProjectionMatrix());
        })

        // update artoolkit on every frame
        onRenderFcts.push(function () {
            if (arToolkitSource.ready === false) return

            arToolkitContext.update(arToolkitSource.domElement)

            // update scene.visible if the marker is seen
            scene.visible = camera.visible
        })

        ////////////////////////////////////////////////////////////////////////////////
        // Create a ArMarkerControls
        ////////////////////////////////////////////////////////////////////////////////

        // init controls for camera
        var markerControls = new THREEx.ArMarkerControls(arToolkitContext, camera, {
            type: 'pattern',
            patternUrl: 'data/patt.inition',
            // as we controls the camera, set changeMatrixMode: 'cameraTransformMatrix'
            changeMatrixMode: 'cameraTransformMatrix'
        })
        // as we do changeMatrixMode: 'cameraTransformMatrix', start with invisible scene
        scene.visible = false

        //////////////////////////////////////////////////////////////////////////////////
        // Add an object in the scene
        //////////////////////////////////////////////////////////////////////////////////

        // add a model
        var loader = new THREE.GLTFLoader();

        loader.load(
            'data/models/mech_drone/scene.gltf',
            function (gltf) {
                scene.add(gltf.scene);
                // scale down
                gltf.scene.scale.set(0.01, 0.01, 0.01);
                // marker on vertical surface so rotate model
                gltf.scene.rotation.x = -Math.PI / 2;
                // origin set at base of model so position to centre
                gltf.scene.position.set(0, 1, 1);
                // get first animation in model and play
                mixer = new THREE.AnimationMixer(gltf.scene);
                mixer.clipAction(gltf.animations[0]).play();
            }
        );

        // update animation on every frame
        onRenderFcts.push(function (delta) {
            if (mixer != undefined)
                mixer.update(delta);
        })

        //////////////////////////////////////////////////////////////////////////////////
        //		render the whole thing on the page
        //////////////////////////////////////////////////////////////////////////////////

        // render the scene
        onRenderFcts.push(function () {
            renderer.render(scene, camera);
        })

        // set up next animation frame and execute frame functions
        function animate() {
            requestAnimationFrame(animate);
            var delta = clock.getDelta();
            onRenderFcts.forEach(function (onRenderFct) {
                onRenderFct(delta);
            })
        }

        // start animation
        animate();

        function takeScreenshot() {
            var w = window.open('', '');
            w.document.title = "Screenshot";
            var img = new Image();
            var secondImg = new Image();
            renderer.render(scene, camera);
            var doubleImageCanvas = document.getElementById('doubleImage');
            var context = doubleImageCanvas.getContext('2d');
            var sources = {
                firstImage: renderer.domElement.toDataURL("image/png"),
                secondImage: arToolkitContext.arController.canvas.toDataURL("image/png")
            };

            loadImages(sources, function (images) {
                context.drawImage(images.secondImage, 0, 0);
                context.drawImage(images.firstImage, 0, 0);
                img.src = doubleImageCanvas.toDataURL("image/png");
                w.document.body.appendChild(img);
            });

            renderer.domElement.toBlob(function (blob) {
                var a = document.createElement('a');
                var url = img.src.replace(/^data:image\/[^;]+/, 'data:application/octet-stream');
                a.href = url;
                a.download = 'canvas.png';
                a.click();
            }, 'image/png', 1.0);
        }

        function downloadScreenshot() {
            var firstImage = new Image();
            var secondImage = new Image();
            var finalCanvas = document.getElementById("doubleImage");
            var context = finalCanvas.getContext("2d");

            renderer.render(scene, camera);

            firstImage.src = renderer.domElement.toDataURL("image/png");
            context.drawImage(firstImage, 0, 0);
            secondImage.src = arToolkitContext.arController.canvas.toDataURL("image/png");
            context.drawImage(secondImage, 0, 0);

            renderer.domElement.toBlob(function (blob) {
                var a = document.createElement('a');
                var url = URL.createObjectURL(blob);
                a.href = url;
                a.download = 'canvas.png';
                a.click();
            });

        }

        function loadImages(sources, callback) {
            var images = {};
            var loadedImages = 0;
            var numImages = 0;
            // get num of sources
            for (var src in sources) {
                numImages++;
            }
            for (var src in sources) {
                images[src] = new Image();
                images[src].onload = function () {
                    if (++loadedImages >= numImages) {
                        callback(images);
                    }
                };
                images[src].src = sources[src];
            }
        }
    </script>
    <canvas width='640' height='480' style='visibility:hidden;' id='doubleImage'></canvas>
    <div style="width:100%;height:50px;position:fixed;bottom:0px;background-color:orange;text-align:center;">
        <div style="font-size:large;display:inline-block; top:50%" onclick="downloadScreenshot()">
            <p>SNAP!</p>
        </div>
    </div>
</body>
